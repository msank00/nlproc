{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Spam Ham Classification](https://www.kaggle.com/aaditkapoor1201/pytorch-spam-ham-classification)\n",
    "\n",
    "## Understanding Checkpoint\n",
    "\n",
    "- [saving-loading-your-model-in-pytorch](https://medium.com/udacity-pytorch-challengers/saving-loading-your-model-in-pytorch-741b80daf3c)\n",
    "- [checkpointing-tutorial-for-tensorflow-keras-and-pytorch](https://blog.floydhub.com/checkpointing-tutorial-for-tensorflow-keras-and-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import spacy #load spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/sankarshan/Documents/code/dataset/textdata/\"\n",
    "DIR_model = \"/home/sankarshan/Documents/code/nlproc/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 354M\r\n",
      " 64M -rwxrwxrwx 1 sankarshan sankarshan  64M Mar  9  2019 IMDB_Dataset.csv\r\n",
      "956K -rw-r--r-- 1 sankarshan sankarshan 956K May  8 21:48 ml-latest-small.zip\r\n",
      "265M -rw-r--r-- 1 sankarshan sankarshan 265M May  8 21:50 ml-latest.zip\r\n",
      "4.0K -rw-r--r-- 1 sankarshan sankarshan   71 Oct 19 23:39 README.md\r\n",
      " 26M -rw-rw-r-- 1 sankarshan sankarshan  26M Oct 19 23:42 imdb-dataset-of-50k-movie-reviews.zip\r\n",
      "4.0K drwxr-xr-x 2 sankarshan sankarshan 4.0K Oct 19 23:43 ml-latest-small\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lshrt {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR+'IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(text):\n",
    "    # Strip HTML tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    " \n",
    "    # Strip escaped quotes\n",
    "    text = text.replace('\\\\\"', '')\n",
    " \n",
    "    # Strip quotes\n",
    "    text = text.replace('\"', '')\n",
    "    \n",
    "    text = text.lower()\n",
    " \n",
    "    return text\n",
    "\n",
    "def normalize(comment, lowercase=True):\n",
    "    if lowercase:\n",
    "        comment = comment.lower()\n",
    "    comment = nlp(comment)\n",
    "    lemmatized = list()\n",
    "    for word in comment:\n",
    "        if not word.is_stop:\n",
    "            lemma = word.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "        \n",
    "    return \" \".join(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'tagger', 'ner'])\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 170 ms, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned_review'] = df['review'].apply(clean_review)\n",
    "df['normalized_review'] = df['cleaned_review'].apply(normalize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>normalized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>reviewer mention watch 1 oz episode hook . rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production.   the filming t...</td>\n",
       "      <td>wonderful little production .  film technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>basically family little boy ( jake ) think zom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's love in the time of money is a...</td>\n",
       "      <td>petter mattei love time money visually stun fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production.   the filming t...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter mattei's love in the time of money is a...   \n",
       "\n",
       "                                   normalized_review  \n",
       "0  reviewer mention watch 1 oz episode hook . rig...  \n",
       "1  wonderful little production .  film technique ...  \n",
       "2  think wonderful way spend time hot summer week...  \n",
       "3  basically family little boy ( jake ) think zom...  \n",
       "4  petter mattei love time money visually stun fi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.  the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.  it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.  i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reviewer mention watch 1 oz episode hook . right , exactly happen .  thing strike oz brutality unflinching scene violence , set right word . trust , faint hearted timid . pull punch regard drug , sex violence . hardcore , classic use word .  call oz nickname give oswald maximum security state penitentary . focus mainly emerald city , experimental section prison cell glass front face inwards , privacy high agendum . -PRON- city home .. aryans , muslims , gangstas , latinos , christians , italians , irish .... scuffle , death stare , dodgy dealings shady agreement far away .  main appeal fact go show dare . forget pretty picture paint mainstream audience , forget charm , forget romance ... oz mess . episode see strike nasty surreal , ready , watch , develope taste oz , get accustom high level graphic violence . violence , injustice ( crook guard sell nickel , inmate kill order away , mannered , middle class inmate turn prison bitch lack street skill prison experience ) watch oz , comfortable uncomfortable view .... thats touch dark .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = df.sentiment.map({\"positive\": 1, \"negative\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.normalized_review.values\n",
    "labels = df.sentiment.values\n",
    "num_words = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(num_words=1000)\n",
    "t.fit_on_texts(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 192 ms, total: 14.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = t.texts_to_matrix(features, mode='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the dimension\n",
    "\n",
    "- `input_dim`: dimension of the input paragraph/review\n",
    "  - remember each input `normalized_review` is transformed into a `1000` dimension vector by keras tokenizer\n",
    "  \n",
    "- `hidden_dim`: denotes the number of neurons in the hidden layer\n",
    "\n",
    "- `output_dim`: denotes the number of category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = num_words\n",
    "hidden_dim = 100\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "\n",
    "class LinNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.l3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # shape of X: (batch_size, input_dim)\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = self.l3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, shuffle=True, random_state=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.NINF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use `checkpoint` in your code?\n",
    "\n",
    "### What is checkpoint?\n",
    "\n",
    "\n",
    "- The architecture of the model, allowing you to re-create the model\n",
    "- The weights of the model\n",
    "- The training configuration (loss, optimizer, epochs, and other meta-information)\n",
    "- The state of the optimizer, allowing to resume training exactly where you left off.\n",
    "\n",
    "> Again, a checkpoint contains the information you need to save your current experiment state so that you can resume training from this point.\n",
    "\n",
    "### How to save and load checkpoint in Pytorch?\n",
    "\n",
    "```py\n",
    "#Saving a checkpoint\n",
    "torch.save(checkpoint, ‘checkpoint.pth’)#Loading a checkpoint\n",
    "checkpoint = torch.load( ‘checkpoint.pth’)\n",
    "```\n",
    "\n",
    "> A checkpoint is a python dictionary that typically includes the following:\n",
    "\n",
    "1. **Network structure:** input and output sizes and Hidden layers to be able to reconstruct the model at loading time.\n",
    "2. **Model state dict:** includes parameters of the network layers that is learned during training, you get it by calling this method on your model instance.\n",
    "`model.state_dict()`\n",
    "3. **Optimizer state dict:** In case you are saving the latest checkpoint to continue training later, you need to save the optimizer’s state as well.\n",
    "you get it by calling this method on an optimizer’s instance `optimizer.state_dict()`\n",
    "4. Additional info: You may need to store additional info, like number of epochs and your class to index mapping in your checkpoint.\n",
    "\n",
    "```py\n",
    "#Example for saving a checkpoint assuming the network class named #Classifier\n",
    "checkpoint = {'model': Classifier(),\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "```\n",
    "\n",
    "```py\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "```\n",
    "\n",
    "\n",
    "**Resource:**\n",
    "- [saving-loading-your-model-in-pytorch](https://medium.com/udacity-pytorch-challengers/saving-loading-your-model-in-pytorch-741b80daf3c)\n",
    "- [checkpointing-tutorial-for-tensorflow-keras-and-pytorch](https://blog.floydhub.com/checkpointing-tutorial-for-tensorflow-keras-and-pytorch/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "    \n",
    "    x_train = Variable(torch.from_numpy(features_train)).float()\n",
    "    y_train = Variable(torch.from_numpy(labels_train)).long()\n",
    "    model.train()\n",
    "    \n",
    "    acc_best = np.NINF\n",
    "    check_flag = False\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "        acc = float(pred)/float(len(x_train))\n",
    "        \n",
    "        if acc > acc_best:\n",
    "            acc_best = acc\n",
    "            state_dict = model.state_dict()\n",
    "            optimizer_state = optimizer.state_dict()\n",
    "            check_flag = True\n",
    "        \n",
    "        status = f\"epoch {epoch+1}/{epochs}\\tloss: {loss.item():.4}\\t acc: {acc:.4}\" \n",
    "        \n",
    "        if check_flag:\n",
    "            status = status + \"\\t >> Best Checkpoint <<\"\n",
    "            check_flag = False\n",
    "        \n",
    "        \n",
    "        print(status)\n",
    "        loss_hist.append(np.round(loss.item(),4))\n",
    "        acc_hist.append(np.round(acc,2))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    checkpoint_best = {\"state_dict\":state_dict, 'optimizer_state': optimizer_state}\n",
    "    \n",
    "    return loss_hist, acc_hist, checkpoint_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epochs):\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "    \n",
    "    model.eval()\n",
    "    x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(labels_test)).long()\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "            \n",
    "            acc = float(pred)/float(len(x_test))\n",
    "            status = f\"epoch {epoch+1}/{epochs}\\tloss: {loss.item()}\\t acc: {acc} %\" \n",
    "            print(status)\n",
    "            \n",
    "            loss_hist.append(np.round(loss.item(),4))\n",
    "            acc_hist.append(np.round(acc,4))\n",
    "    \n",
    "    return loss_hist, acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinNet(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100\tloss: 0.6997\t acc: 0.4941\t >> Best Checkpoint <<\n",
      "epoch 2/100\tloss: 0.7601\t acc: 0.5013\t >> Best Checkpoint <<\n",
      "epoch 3/100\tloss: 0.6909\t acc: 0.4996\n",
      "epoch 4/100\tloss: 0.6337\t acc: 0.5425\t >> Best Checkpoint <<\n",
      "epoch 5/100\tloss: 0.5488\t acc: 0.7947\t >> Best Checkpoint <<\n",
      "epoch 6/100\tloss: 0.4846\t acc: 0.8038\t >> Best Checkpoint <<\n",
      "epoch 7/100\tloss: 0.4506\t acc: 0.807\t >> Best Checkpoint <<\n",
      "epoch 8/100\tloss: 0.4237\t acc: 0.8259\t >> Best Checkpoint <<\n",
      "epoch 9/100\tloss: 0.3811\t acc: 0.8432\t >> Best Checkpoint <<\n",
      "epoch 10/100\tloss: 0.3685\t acc: 0.8504\t >> Best Checkpoint <<\n",
      "epoch 11/100\tloss: 0.362\t acc: 0.8525\t >> Best Checkpoint <<\n",
      "epoch 12/100\tloss: 0.334\t acc: 0.8655\t >> Best Checkpoint <<\n",
      "epoch 13/100\tloss: 0.3291\t acc: 0.8655\n",
      "epoch 14/100\tloss: 0.334\t acc: 0.8594\n",
      "epoch 15/100\tloss: 0.3193\t acc: 0.8661\t >> Best Checkpoint <<\n",
      "epoch 16/100\tloss: 0.3253\t acc: 0.8624\n",
      "epoch 17/100\tloss: 0.3138\t acc: 0.8674\t >> Best Checkpoint <<\n",
      "epoch 18/100\tloss: 0.3103\t acc: 0.8689\t >> Best Checkpoint <<\n",
      "epoch 19/100\tloss: 0.3086\t acc: 0.8714\t >> Best Checkpoint <<\n",
      "epoch 20/100\tloss: 0.3007\t acc: 0.8737\t >> Best Checkpoint <<\n",
      "epoch 21/100\tloss: 0.3017\t acc: 0.8734\n",
      "epoch 22/100\tloss: 0.2946\t acc: 0.8754\t >> Best Checkpoint <<\n",
      "epoch 23/100\tloss: 0.2965\t acc: 0.8738\n",
      "epoch 24/100\tloss: 0.2908\t acc: 0.8767\t >> Best Checkpoint <<\n",
      "epoch 25/100\tloss: 0.2919\t acc: 0.8772\t >> Best Checkpoint <<\n",
      "epoch 26/100\tloss: 0.2862\t acc: 0.8783\t >> Best Checkpoint <<\n",
      "epoch 27/100\tloss: 0.2862\t acc: 0.8767\n",
      "epoch 28/100\tloss: 0.2813\t acc: 0.8805\t >> Best Checkpoint <<\n",
      "epoch 29/100\tloss: 0.2806\t acc: 0.8803\n",
      "epoch 30/100\tloss: 0.2758\t acc: 0.8811\t >> Best Checkpoint <<\n",
      "epoch 31/100\tloss: 0.2733\t acc: 0.8823\t >> Best Checkpoint <<\n",
      "epoch 32/100\tloss: 0.2695\t acc: 0.8845\t >> Best Checkpoint <<\n",
      "epoch 33/100\tloss: 0.2663\t acc: 0.8857\t >> Best Checkpoint <<\n",
      "epoch 34/100\tloss: 0.2627\t acc: 0.8859\t >> Best Checkpoint <<\n",
      "epoch 35/100\tloss: 0.2579\t acc: 0.8892\t >> Best Checkpoint <<\n",
      "epoch 36/100\tloss: 0.255\t acc: 0.8902\t >> Best Checkpoint <<\n",
      "epoch 37/100\tloss: 0.2498\t acc: 0.893\t >> Best Checkpoint <<\n",
      "epoch 38/100\tloss: 0.245\t acc: 0.8955\t >> Best Checkpoint <<\n",
      "epoch 39/100\tloss: 0.241\t acc: 0.8973\t >> Best Checkpoint <<\n",
      "epoch 40/100\tloss: 0.2354\t acc: 0.9\t >> Best Checkpoint <<\n",
      "epoch 41/100\tloss: 0.2303\t acc: 0.9025\t >> Best Checkpoint <<\n",
      "epoch 42/100\tloss: 0.2257\t acc: 0.9037\t >> Best Checkpoint <<\n",
      "epoch 43/100\tloss: 0.2204\t acc: 0.9063\t >> Best Checkpoint <<\n",
      "epoch 44/100\tloss: 0.2148\t acc: 0.9085\t >> Best Checkpoint <<\n",
      "epoch 45/100\tloss: 0.2087\t acc: 0.9119\t >> Best Checkpoint <<\n",
      "epoch 46/100\tloss: 0.2033\t acc: 0.9144\t >> Best Checkpoint <<\n",
      "epoch 47/100\tloss: 0.198\t acc: 0.9162\t >> Best Checkpoint <<\n",
      "epoch 48/100\tloss: 0.1944\t acc: 0.9177\t >> Best Checkpoint <<\n",
      "epoch 49/100\tloss: 0.1946\t acc: 0.9175\n",
      "epoch 50/100\tloss: 0.1995\t acc: 0.9118\n",
      "epoch 51/100\tloss: 0.1887\t acc: 0.9211\t >> Best Checkpoint <<\n",
      "epoch 52/100\tloss: 0.1747\t acc: 0.9275\t >> Best Checkpoint <<\n",
      "epoch 53/100\tloss: 0.1786\t acc: 0.9221\n",
      "epoch 54/100\tloss: 0.1754\t acc: 0.926\n",
      "epoch 55/100\tloss: 0.1634\t acc: 0.9318\t >> Best Checkpoint <<\n",
      "epoch 56/100\tloss: 0.1601\t acc: 0.9339\t >> Best Checkpoint <<\n",
      "epoch 57/100\tloss: 0.159\t acc: 0.935\t >> Best Checkpoint <<\n",
      "epoch 58/100\tloss: 0.1506\t acc: 0.9376\t >> Best Checkpoint <<\n",
      "epoch 59/100\tloss: 0.1471\t acc: 0.9394\t >> Best Checkpoint <<\n",
      "epoch 60/100\tloss: 0.1456\t acc: 0.9391\n",
      "epoch 61/100\tloss: 0.1403\t acc: 0.9426\t >> Best Checkpoint <<\n",
      "epoch 62/100\tloss: 0.135\t acc: 0.9456\t >> Best Checkpoint <<\n",
      "epoch 63/100\tloss: 0.1319\t acc: 0.9468\t >> Best Checkpoint <<\n",
      "epoch 64/100\tloss: 0.1283\t acc: 0.948\t >> Best Checkpoint <<\n",
      "epoch 65/100\tloss: 0.1256\t acc: 0.9494\t >> Best Checkpoint <<\n",
      "epoch 66/100\tloss: 0.1218\t acc: 0.9508\t >> Best Checkpoint <<\n",
      "epoch 67/100\tloss: 0.1166\t acc: 0.9537\t >> Best Checkpoint <<\n",
      "epoch 68/100\tloss: 0.1132\t acc: 0.9552\t >> Best Checkpoint <<\n",
      "epoch 69/100\tloss: 0.1085\t acc: 0.9573\t >> Best Checkpoint <<\n",
      "epoch 70/100\tloss: 0.1056\t acc: 0.9586\t >> Best Checkpoint <<\n",
      "epoch 71/100\tloss: 0.102\t acc: 0.9599\t >> Best Checkpoint <<\n",
      "epoch 72/100\tloss: 0.09932\t acc: 0.9608\t >> Best Checkpoint <<\n",
      "epoch 73/100\tloss: 0.09875\t acc: 0.9615\t >> Best Checkpoint <<\n",
      "epoch 74/100\tloss: 0.1044\t acc: 0.9567\n",
      "epoch 75/100\tloss: 0.135\t acc: 0.9386\n",
      "epoch 76/100\tloss: 0.1699\t acc: 0.9211\n",
      "epoch 77/100\tloss: 0.142\t acc: 0.9364\n",
      "epoch 78/100\tloss: 0.1045\t acc: 0.9598\n",
      "epoch 79/100\tloss: 0.1167\t acc: 0.9498\n",
      "epoch 80/100\tloss: 0.09809\t acc: 0.96\n",
      "epoch 81/100\tloss: 0.09982\t acc: 0.959\n",
      "epoch 82/100\tloss: 0.09687\t acc: 0.9602\n",
      "epoch 83/100\tloss: 0.09443\t acc: 0.9605\n",
      "epoch 84/100\tloss: 0.08883\t acc: 0.9623\t >> Best Checkpoint <<\n",
      "epoch 85/100\tloss: 0.08204\t acc: 0.9681\t >> Best Checkpoint <<\n",
      "epoch 86/100\tloss: 0.08503\t acc: 0.9686\t >> Best Checkpoint <<\n",
      "epoch 87/100\tloss: 0.08185\t acc: 0.97\t >> Best Checkpoint <<\n",
      "epoch 88/100\tloss: 0.07977\t acc: 0.9703\t >> Best Checkpoint <<\n",
      "epoch 89/100\tloss: 0.07509\t acc: 0.9725\t >> Best Checkpoint <<\n",
      "epoch 90/100\tloss: 0.07117\t acc: 0.9733\t >> Best Checkpoint <<\n",
      "epoch 91/100\tloss: 0.07081\t acc: 0.9724\n",
      "epoch 92/100\tloss: 0.06844\t acc: 0.973\n",
      "epoch 93/100\tloss: 0.06661\t acc: 0.9739\t >> Best Checkpoint <<\n",
      "epoch 94/100\tloss: 0.06256\t acc: 0.9759\t >> Best Checkpoint <<\n",
      "epoch 95/100\tloss: 0.05964\t acc: 0.9786\t >> Best Checkpoint <<\n",
      "epoch 96/100\tloss: 0.05777\t acc: 0.9798\t >> Best Checkpoint <<\n",
      "epoch 97/100\tloss: 0.05704\t acc: 0.9804\t >> Best Checkpoint <<\n",
      "epoch 98/100\tloss: 0.0548\t acc: 0.9815\t >> Best Checkpoint <<\n",
      "epoch 99/100\tloss: 0.05219\t acc: 0.983\t >> Best Checkpoint <<\n",
      "epoch 100/100\tloss: 0.05025\t acc: 0.9826\n",
      "CPU times: user 1min 15s, sys: 18.8 s, total: 1min 34s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_hist, acc_hist, checkpoint_best = train(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model (best checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': LinNet(input_dim, hidden_dim, output_dim),\n",
    "              'state_dict': checkpoint_best['state_dict'],\n",
    "              'optimizer' : checkpoint_best['optimizer_state']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.65 ms, sys: 8.18 ms, total: 13.8 ms\n",
      "Wall time: 4.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(checkpoint, DIR_model+'review_classification_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model aka checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    #model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = load_checkpoint(DIR_model+'review_classification_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 2/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 3/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 4/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 5/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 6/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 7/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 8/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 9/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 10/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 11/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 12/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 13/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 14/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 15/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 16/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 17/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 18/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 19/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 20/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 21/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 22/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 23/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 24/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 25/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 26/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 27/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 28/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 29/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 30/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 31/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 32/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 33/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 34/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 35/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 36/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 37/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 38/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 39/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 40/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 41/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 42/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 43/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 44/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 45/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 46/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 47/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 48/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 49/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 50/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 51/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 52/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 53/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 54/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 55/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 56/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 57/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 58/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 59/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 60/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 61/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 62/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 63/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 64/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 65/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 66/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 67/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 68/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 69/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 70/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 71/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 72/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 73/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 74/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 75/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 76/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 77/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 78/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 79/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 80/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 81/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 82/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 83/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 84/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 85/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 86/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 87/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 88/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 89/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 90/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 91/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 92/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 93/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 94/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 95/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 96/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 97/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 98/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 99/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n",
      "epoch 100/100\tloss: 1.1033885478973389\t acc: 0.82568 %\n"
     ]
    }
   ],
   "source": [
    "test_loss_hist, test_acc_hist = test(model_test, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Values')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_hist, label = \"train loss\")\n",
    "plt.plot(acc_hist ,label=\"train acc\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.ylabel(\"Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
